{
  "id": "snapshot_1765811493669_i49vc9thy",
  "approvalId": "approval_1765811436687_3och9wvbc",
  "approvalTitle": "MVP Design Document",
  "version": 2,
  "timestamp": "2025-12-15T15:11:33.669Z",
  "trigger": "revision_requested",
  "status": "pending",
  "content": "# Design Document - MVP (CLI-First)\n\n## Overview\n\nThe Code-Viz MVP is architected as a **dual-crate Rust project**: a library crate (`code-viz-core`) containing pure analysis logic, and a binary crate (`code-viz-cli`) providing the command-line interface. This separation enables:\n\n- **Library-first design**: Core analysis engine is CLI-agnostic and can be embedded in future GUI applications, web servers, or language server protocols\n- **Fast iteration**: CLI changes (argument parsing, output formatting) don't require recompiling the analysis engine\n- **Testability**: Pure functions in library crate are easy to unit test without mocking I/O\n\nThe system follows a **pipeline architecture**:\n```\nFile Discovery → Parsing (Tree-sitter) → Metrics Calculation → Output Formatting\n```\n\nEach stage is independently testable and can be parallelized using Rayon.\n\n## Steering Document Alignment\n\n### Technical Standards (tech.md)\n\n- **Rust 1.75+**: Primary language for both crates\n- **Tree-sitter 0.20+**: Multi-language parsing with incremental capabilities\n- **Performance Targets**:\n  - Startup: <50ms for `--help`\n  - Analysis: <30s for 100K files (using rayon for parallelism)\n  - Watch mode: <100ms incremental updates (leveraging Tree-sitter's incremental parsing)\n- **Compilation Acceleration**:\n  - Mold linker configured in `.cargo/config.toml`\n  - Sccache for shared compilation cache\n  - Justfile for dev/test/build recipes\n- **Testing**: cargo-nextest for parallel test execution, insta for snapshot testing\n- **Logging**: tracing crate with structured JSON logs to stderr\n\n### Project Structure (structure.md)\n\n```\ncode-viz/\n├── crates/\n│   ├── code-viz-core/          # Library crate (analysis engine)\n│   │   ├── src/\n│   │   │   ├── lib.rs          # Public API exports\n│   │   │   ├── scanner.rs      # File discovery with exclusions\n│   │   │   ├── parser.rs       # Tree-sitter wrapper (trait-based)\n│   │   │   ├── metrics.rs      # LOC and function counting\n│   │   │   ├── analyzer.rs     # Orchestrates scan → parse → metrics\n│   │   │   ├── models.rs       # Data structures (FileMetrics, AnalysisResult)\n│   │   │   └── cache.rs        # Disk-based caching (.code-viz/cache)\n│   │   ├── Cargo.toml\n│   │   └── tests/\n│   │       ├── integration_test.rs\n│   │       └── snapshots/      # Insta snapshot files\n│   │\n│   └── code-viz-cli/           # Binary crate (CLI interface)\n│       ├── src/\n│       │   ├── main.rs         # Entry point, command dispatcher\n│       │   ├── commands/\n│       │   │   ├── mod.rs\n│       │   │   ├── analyze.rs  # `analyze` command logic\n│       │   │   ├── watch.rs    # `watch` command with notify integration\n│       │   │   ├── diff.rs     # `diff` command for comparing reports\n│       │   │   └── config.rs   # `config init` command\n│       │   ├── output/\n│       │   │   ├── mod.rs\n│       │   │   ├── json.rs     # JSON formatter\n│       │   │   ├── csv.rs      # CSV formatter\n│       │   │   └── text.rs     # Human-readable text formatter\n│       │   └── config_loader.rs # .code-viz.toml parsing\n│       ├── Cargo.toml\n│       └── tests/\n│           └── cli_tests.rs    # Integration tests with temp dirs\n│\n├── .cargo/\n│   └── config.toml             # Linker configuration (mold)\n├── Justfile                    # Task runner recipes\n├── Cargo.toml                  # Workspace manifest\n└── README.md\n```\n\n**Naming Conventions**:\n- Rust files: `snake_case.rs`\n- Structs/Enums: `PascalCase`\n- Functions: `snake_case`\n- Constants: `SCREAMING_SNAKE_CASE`\n\n**Module Boundaries**:\n- `code-viz-core` has NO dependencies on `clap`, `notify`, or any CLI-specific crates\n- `code-viz-cli` depends on `code-viz-core` but not vice versa\n- Communication via public API defined in `code-viz-core/src/lib.rs`\n\n## Code Reuse Analysis\n\nSince this is a greenfield project, there's no existing codebase to leverage. However, we establish **reusable patterns** from the start:\n\n### Foundation for Future Features\n\n- **`parser.rs` trait system**: Designed to support adding new languages (Go, Java, C++) without modifying core logic\n  ```rust\n  pub trait LanguageParser {\n      fn parse(&self, source: &str) -> Result<ParseTree, ParseError>;\n      fn count_functions(&self, tree: &ParseTree) -> usize;\n  }\n  ```\n\n- **`output/` formatters**: Implementing `MetricsFormatter` trait allows adding new formats (Prometheus, XML) as plugins\n  ```rust\n  pub trait MetricsFormatter {\n      fn format(&self, result: &AnalysisResult) -> Result<String, FormatterError>;\n  }\n  ```\n\n- **`cache.rs` abstraction**: Designed to swap backends (sled → SQLite → rocksdb) without changing analyzer logic\n\n### Integration Points\n\n- **Git integration (future)**: `AnalysisResult` includes `last_modified` timestamp; can later correlate with Git commits\n- **GUI integration (future)**: CLI can output newline-delimited JSON stream that GUI consumes via subprocess\n- **LSP integration (future)**: Library crate can be embedded in language server for real-time diagnostics\n\n## Architecture\n\n### System Architecture Diagram\n\n```mermaid\ngraph TB\n    User[User/CI Pipeline] -->|runs| CLI[CLI Binary<br/>code-viz-cli]\n\n    CLI --> ArgParser[Argument Parser<br/>clap]\n    ArgParser --> CmdAnalyze[analyze command]\n    ArgParser --> CmdWatch[watch command]\n    ArgParser --> CmdDiff[diff command]\n\n    CmdAnalyze --> ConfigLoader[Config Loader<br/>.code-viz.toml]\n    ConfigLoader --> CoreAPI[Core API<br/>code-viz-core]\n\n    CoreAPI --> Scanner[File Scanner<br/>scanner.rs]\n    Scanner -->|paths| Parser[Language Parser<br/>parser.rs + Tree-sitter]\n    Parser -->|AST| Metrics[Metrics Calculator<br/>metrics.rs]\n    Metrics -->|results| Aggregator[Aggregator<br/>analyzer.rs]\n\n    Aggregator --> Cache[(Cache<br/>.code-viz/cache)]\n    Aggregator --> Result[AnalysisResult]\n\n    Result --> Formatter[Output Formatter<br/>output/]\n    Formatter --> JSON[JSON]\n    Formatter --> CSV[CSV]\n    Formatter --> Text[Text Summary]\n\n    JSON --> Stdout[stdout]\n    CSV --> Stdout\n    Text --> Stdout\n\n    CmdWatch --> Watcher[File Watcher<br/>notify]\n    Watcher -->|file changed| CoreAPI\n\n    style CoreAPI fill:#e1f5e1\n    style CLI fill:#e3f2fd\n    style Cache fill:#fff4e6\n```\n\n### Modular Design Principles\n\n- **Single File Responsibility**:\n  - `scanner.rs`: File discovery and filtering (glob patterns, exclusions)\n  - `parser.rs`: Tree-sitter abstraction (language-agnostic interface)\n  - `metrics.rs`: Metric calculation algorithms (LOC, function counting)\n  - `analyzer.rs`: Orchestration (scan → parse → metrics → aggregate)\n\n- **Component Isolation**:\n  - Each component exposes a minimal public API (1-3 functions)\n  - Internal helpers are private (`pub(crate)` for cross-module sharing within crate)\n  - No global state; all functions are pure or take explicit dependencies\n\n- **Service Layer Separation**:\n  - **Data Access**: `cache.rs` abstracts disk I/O\n  - **Business Logic**: `analyzer.rs`, `metrics.rs` are pure computation\n  - **Presentation**: `output/` modules handle formatting concerns\n\n## Components and Interfaces\n\n### Component 1: File Scanner (`scanner.rs`)\n\n- **Purpose**: Discover all files in a directory tree, respecting exclusion patterns\n- **Public API**:\n  ```rust\n  pub fn scan_directory(\n      path: &Path,\n      exclude_patterns: &[String],\n  ) -> Result<Vec<PathBuf>, ScanError>;\n  ```\n- **Dependencies**:\n  - `std::fs` for directory traversal\n  - `globset` crate for pattern matching\n- **Algorithm**:\n  1. Use `walkdir` crate for recursive traversal\n  2. Apply exclusion patterns as early filter (skip entire `node_modules/` tree)\n  3. Filter by file extension (`.rs`, `.ts`, `.js`, `.py`)\n  4. Return sorted list of paths (alphabetical for deterministic output)\n- **Performance**: Parallelized using `rayon::par_iter` for multi-core machines\n\n### Component 2: Language Parser (`parser.rs`)\n\n- **Purpose**: Abstract Tree-sitter parsing for multiple languages\n- **Public API**:\n  ```rust\n  pub trait LanguageParser: Send + Sync {\n      fn language(&self) -> &str; // \"rust\", \"typescript\", etc.\n      fn parse(&self, source: &str) -> Result<Tree, ParseError>;\n      fn count_functions(&self, tree: &Tree) -> usize;\n  }\n\n  pub struct RustParser { /* Tree-sitter instance */ }\n  impl LanguageParser for RustParser { /* ... */ }\n\n  pub struct TypeScriptParser { /* Tree-sitter instance */ }\n  impl LanguageParser for TypeScriptParser { /* ... */ }\n\n  pub fn get_parser(language: &str) -> Result<Box<dyn LanguageParser>, ParserError>;\n  ```\n- **Dependencies**:\n  - `tree-sitter` core library\n  - `tree-sitter-rust`, `tree-sitter-typescript`, etc. (language grammars)\n- **Implementation Notes**:\n  - Each parser implementation wraps a `tree_sitter::Parser` with language-specific grammar\n  - Function counting uses Tree-sitter queries (S-expression patterns):\n    ```scheme\n    ;; Rust query\n    (function_item) @function\n    (impl_item (function_item)) @method\n    ```\n  - Parsers are cached in a `OnceCell` for reuse across files\n\n### Component 3: Metrics Calculator (`metrics.rs`)\n\n- **Purpose**: Calculate code metrics from parsed syntax trees and raw source\n- **Public API**:\n  ```rust\n  pub struct FileMetrics {\n      pub path: PathBuf,\n      pub language: String,\n      pub loc: usize,              // Lines of Code (excluding comments/blanks)\n      pub size_bytes: u64,\n      pub function_count: usize,\n      pub last_modified: SystemTime,\n  }\n\n  pub fn calculate_metrics(\n      path: &Path,\n      source: &str,\n      parser: &dyn LanguageParser,\n  ) -> Result<FileMetrics, MetricsError>;\n  ```\n- **Dependencies**: Parser component, `std::fs::metadata` for file info\n- **Algorithm**:\n  1. **LOC Calculation**:\n     - Parse source with Tree-sitter\n     - Traverse AST, identify comment nodes\n     - Count non-blank lines that don't overlap with comment byte ranges\n  2. **Function Counting**: Delegate to `parser.count_functions(tree)`\n  3. **File Metadata**: Extract size and modified time from `fs::metadata`\n- **Edge Cases**:\n  - Mixed-line comments: `code(); // comment` counts as 1 LOC\n  - Parse errors: Return `MetricsError::ParseFailed`, caller continues with other files\n\n### Component 4: Analysis Orchestrator (`analyzer.rs`)\n\n- **Purpose**: High-level API that orchestrates scan → parse → metrics pipeline\n- **Public API**:\n  ```rust\n  pub struct AnalysisResult {\n      pub summary: Summary,\n      pub files: Vec<FileMetrics>,\n      pub timestamp: SystemTime,\n  }\n\n  pub struct Summary {\n      pub total_files: usize,\n      pub total_loc: usize,\n      pub total_functions: usize,\n      pub largest_files: Vec<PathBuf>, // Top 10 by LOC\n  }\n\n  pub struct AnalysisConfig {\n      pub exclude_patterns: Vec<String>,\n      pub use_cache: bool,\n  }\n\n  pub fn analyze(\n      root: &Path,\n      config: &AnalysisConfig,\n  ) -> Result<AnalysisResult, AnalysisError>;\n  ```\n- **Dependencies**: Scanner, Parser, Metrics, Cache\n- **Flow**:\n  1. Call `scanner::scan_directory(root, config.exclude_patterns)`\n  2. For each file (parallelized with `rayon::par_iter`):\n     - Check cache: if file mtime unchanged, use cached metrics\n     - Else: read source, parse, calculate metrics\n     - Store in cache\n  3. Aggregate metrics into `Summary`\n  4. Return `AnalysisResult`\n- **Parallelism**: Uses `rayon::ThreadPoolBuilder` with CPU core count\n\n### Component 5: Cache Layer (`cache.rs`)\n\n- **Purpose**: Persist analysis results to disk for fast re-analysis\n- **Public API**:\n  ```rust\n  pub struct DiskCache {\n      path: PathBuf, // .code-viz/cache\n  }\n\n  impl DiskCache {\n      pub fn new(cache_dir: PathBuf) -> Result<Self, CacheError>;\n\n      pub fn get(&self, file_path: &Path) -> Option<FileMetrics>;\n\n      pub fn set(&self, metrics: &FileMetrics) -> Result<(), CacheError>;\n\n      pub fn invalidate(&self, file_path: &Path) -> Result<(), CacheError>;\n  }\n  ```\n- **Dependencies**: `serde` for serialization, `bincode` for binary format\n- **Storage Format**:\n  - Key: SHA-256 hash of `file_path`\n  - Value: `bincode`-serialized `FileMetrics` struct\n  - File: `.code-viz/cache/<hash>.bin`\n- **Cache Invalidation**: Compare file's `last_modified` time; if different, ignore cache\n\n### Component 6: Output Formatters (`output/`)\n\n- **Purpose**: Convert `AnalysisResult` to various output formats\n- **Public API**:\n  ```rust\n  pub trait MetricsFormatter {\n      fn format(&self, result: &AnalysisResult) -> Result<String, FormatterError>;\n  }\n\n  pub struct JsonFormatter;\n  impl MetricsFormatter for JsonFormatter { /* serde_json */ }\n\n  pub struct CsvFormatter;\n  impl MetricsFormatter for CsvFormatter { /* csv crate */ }\n\n  pub struct TextFormatter;\n  impl MetricsFormatter for TextFormatter { /* pretty tables */ }\n  ```\n- **Dependencies**: `serde_json`, `csv`, `prettytable-rs`\n- **Implementations**:\n  - **JSON**: Serialize entire `AnalysisResult` struct\n  - **CSV**: Flatten `files` array to rows (path, language, loc, functions, size_bytes)\n  - **Text**: ASCII table with summary + top 10 largest files\n\n### Component 7: Watch Mode (`commands/watch.rs`)\n\n- **Purpose**: Monitor file system for changes and trigger incremental re-analysis\n- **Public API** (internal to CLI, not in lib):\n  ```rust\n  pub fn run_watch(\n      root: PathBuf,\n      config: AnalysisConfig,\n      formatter: Box<dyn MetricsFormatter>,\n  ) -> Result<(), WatchError>;\n  ```\n- **Dependencies**: `notify` crate (file watcher), `code-viz-core::analyze`\n- **Flow**:\n  1. Perform initial analysis, print results\n  2. Create `notify::RecommendedWatcher` for `root` directory\n  3. On file event:\n     - Debounce: collect events for 100ms\n     - Filter: only re-analyze changed files (not entire tree)\n     - Call `analyze` on subset of files\n     - Print updated metrics to stdout\n  4. Run until Ctrl+C (SIGINT)\n- **Output Format**: Newline-delimited JSON for `--format json` mode\n\n## Data Models\n\n### FileMetrics\n\n```rust\nuse serde::{Deserialize, Serialize};\nuse std::path::PathBuf;\nuse std::time::SystemTime;\n\n#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]\npub struct FileMetrics {\n    /// Relative path from repository root\n    pub path: PathBuf,\n\n    /// Programming language (\"rust\", \"typescript\", \"python\", etc.)\n    pub language: String,\n\n    /// Lines of code (excluding comments and blank lines)\n    pub loc: usize,\n\n    /// File size in bytes\n    pub size_bytes: u64,\n\n    /// Number of functions/methods\n    pub function_count: usize,\n\n    /// Last modified timestamp (for cache invalidation)\n    pub last_modified: SystemTime,\n}\n```\n\n### AnalysisResult\n\n```rust\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct AnalysisResult {\n    /// Aggregated summary statistics\n    pub summary: Summary,\n\n    /// Per-file metrics\n    pub files: Vec<FileMetrics>,\n\n    /// When this analysis was performed\n    pub timestamp: SystemTime,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct Summary {\n    /// Total number of files analyzed\n    pub total_files: usize,\n\n    /// Total lines of code across all files\n    pub total_loc: usize,\n\n    /// Total functions across all files\n    pub total_functions: usize,\n\n    /// Top 10 largest files by LOC (sorted descending)\n    pub largest_files: Vec<PathBuf>,\n}\n```\n\n### AnalysisConfig\n\n```rust\n#[derive(Debug, Clone)]\npub struct AnalysisConfig {\n    /// Glob patterns to exclude (e.g., \"node_modules/**\")\n    pub exclude_patterns: Vec<String>,\n\n    /// Whether to use disk cache for unchanged files\n    pub use_cache: bool,\n}\n\nimpl Default for AnalysisConfig {\n    fn default() -> Self {\n        Self {\n            exclude_patterns: vec![\n                \"node_modules/**\".into(),\n                \"target/**\".into(),\n                \".git/**\".into(),\n                \"dist/**\".into(),\n                \"build/**\".into(),\n            ],\n            use_cache: true,\n        }\n    }\n}\n```\n\n### .code-viz.toml Config File\n\n```toml\n[analysis]\n# Glob patterns to exclude\nexclude = [\n    \"**/generated/**\",\n    \"**/*.test.ts\",\n]\n\n[output]\n# Default output format: \"json\", \"csv\", or \"text\"\nformat = \"json\"\n\n[cache]\n# Enable or disable caching\nenabled = true\n```\n\nParsed using `toml` crate into:\n```rust\n#[derive(Debug, Deserialize)]\npub struct ConfigFile {\n    pub analysis: Option<AnalysisConfigSection>,\n    pub output: Option<OutputConfigSection>,\n    pub cache: Option<CacheConfigSection>,\n}\n```\n\n## Error Handling\n\nFollows Rust best practices: use `Result<T, E>` everywhere, define custom error types with `thiserror`.\n\n### Error Types Hierarchy\n\n```rust\nuse thiserror::Error;\n\n#[derive(Error, Debug)]\npub enum AnalysisError {\n    #[error(\"Failed to scan directory: {0}\")]\n    ScanFailed(#[from] ScanError),\n\n    #[error(\"Parse error in {path}: {source}\")]\n    ParseFailed {\n        path: PathBuf,\n        source: ParseError,\n    },\n\n    #[error(\"Cache error: {0}\")]\n    CacheFailed(#[from] CacheError),\n\n    #[error(\"I/O error: {0}\")]\n    IoError(#[from] std::io::Error),\n}\n\n#[derive(Error, Debug)]\npub enum ParseError {\n    #[error(\"Unsupported language: {0}\")]\n    UnsupportedLanguage(String),\n\n    #[error(\"Tree-sitter parse failed: {0}\")]\n    TreeSitterError(String),\n}\n\n#[derive(Error, Debug)]\npub enum ScanError {\n    #[error(\"Invalid glob pattern: {0}\")]\n    InvalidPattern(String),\n\n    #[error(\"Access denied: {0}\")]\n    PermissionDenied(PathBuf),\n}\n```\n\n### Error Handling Strategies\n\n1. **Library Crate (`code-viz-core`)**:\n   - Return `Result` types\n   - Provide context with error variants (include file paths, line numbers)\n   - Graceful degradation: if one file fails to parse, log warning and continue\n\n2. **CLI Crate (`code-viz-cli`)**:\n   - Convert errors to user-friendly messages:\n     ```rust\n     Err(AnalysisError::ParseFailed { path, source }) => {\n         eprintln!(\"ERROR: Failed to parse {}: {}\", path.display(), source);\n         std::process::exit(1);\n     }\n     ```\n   - Use `env_logger` or `tracing` for debug output when `--verbose` flag is set\n\n3. **Watch Mode Errors**:\n   - Don't exit on single-file errors (print to stderr, continue watching)\n   - Exit on fatal errors (file watcher failed to initialize)\n\n### Exit Codes (POSIX Standard)\n\n- `0`: Success\n- `1`: General error (parse failure, cache error)\n- `2`: Invalid arguments (wrong command, missing required option)\n- `3`: Threshold violation (e.g., `--threshold loc=500` exceeded)\n\n## Testing Strategy\n\n### Unit Testing (`code-viz-core`)\n\n- **Snapshot Testing with `insta`**:\n  - Parse fixtures (small `.rs`, `.ts` files) and snapshot the resulting `FileMetrics`\n  - Test LOC calculation edge cases (mixed-line comments, multiline strings)\n  - Example:\n    ```rust\n    #[test]\n    fn test_rust_loc_with_comments() {\n        let source = include_str!(\"fixtures/commented.rs\");\n        let metrics = calculate_metrics(Path::new(\"test.rs\"), source, &RustParser::new()).unwrap();\n        insta::assert_yaml_snapshot!(metrics);\n    }\n    ```\n\n- **Property-Based Testing with `proptest`**:\n  - Generate random code snippets, ensure LOC is always ≤ total lines\n  - Ensure function count is always ≥ 0\n\n- **Mocking**: None needed (pure functions, dependency injection via traits)\n\n### Integration Testing (`code-viz-core/tests/`)\n\n- Create temporary directories with known file structures\n- Run `analyze()` and verify `AnalysisResult`\n- Test cache hit/miss behavior (modify file, re-analyze, verify cache invalidation)\n\n### CLI Integration Testing (`code-viz-cli/tests/`)\n\n- Use `assert_cmd` crate to invoke CLI binary\n- Verify stdout/stderr output\n- Example:\n  ```rust\n  use assert_cmd::Command;\n\n  #[test]\n  fn test_analyze_json_output() {\n      let mut cmd = Command::cargo_bin(\"code-viz\").unwrap();\n      cmd.arg(\"analyze\")\n         .arg(\"tests/fixtures/sample_repo\")\n         .arg(\"--format\").arg(\"json\");\n\n      let output = cmd.output().unwrap();\n      assert!(output.status.success());\n\n      let result: AnalysisResult = serde_json::from_slice(&output.stdout).unwrap();\n      assert_eq!(result.summary.total_files, 5);\n  }\n  ```\n\n### End-to-End Testing\n\n- **Manual Testing**: Smoke test on real-world repositories (Rust compiler, React codebase)\n- **CI Pipeline**: GitHub Actions workflow that runs:\n  1. `cargo test --all-features` (all unit + integration tests)\n  2. `cargo clippy -- -D warnings` (lint check)\n  3. `cargo fmt --check` (formatting check)\n  4. `code-viz analyze .` on the code-viz repository itself (dogfooding)\n\n### Performance Regression Testing\n\n- Benchmark suite using `criterion` crate:\n  - Measure parse time for 1K, 10K, 100K files\n  - Track LOC calculation speed (lines/sec)\n  - Alert if performance degrades >10% between commits\n\n## Implementation Phases\n\n### Phase 1: Core Engine (Week 1)\n\n**Goal**: Working analysis engine for TypeScript/JavaScript\n\n**Tasks**:\n1. Set up Cargo workspace (`code-viz-core` + `code-viz-cli` crates)\n2. Implement `scanner.rs` (file discovery with exclusions)\n3. Implement `parser.rs` (Tree-sitter wrapper for TypeScript only)\n4. Implement `metrics.rs` (LOC calculation, function counting)\n5. Write unit tests + snapshot tests\n\n**Deliverable**: `code-viz-core` crate with public API, 80% test coverage\n\n### Phase 2: CLI Interface (Week 2)\n\n**Goal**: Functional `analyze` command\n\n**Tasks**:\n1. Set up `clap` argument parsing (`analyze <path> --format <fmt>`)\n2. Implement `output/json.rs`, `output/text.rs` formatters\n3. Integrate `code-viz-core::analyze()` in CLI\n4. Add default exclusion patterns\n5. Write CLI integration tests\n\n**Deliverable**: Working `code-viz analyze .` command\n\n### Phase 3: Watch Mode (Week 3)\n\n**Goal**: Real-time monitoring with `watch` command\n\n**Tasks**:\n1. Integrate `notify` crate for file system watching\n2. Implement debouncing logic (collect events for 100ms, batch analyze)\n3. Incremental re-analysis (only changed files)\n4. Newline-delimited JSON stream output\n5. Handle errors gracefully (don't crash on single-file error)\n\n**Deliverable**: `code-viz watch . --format json` streaming metrics\n\n### Phase 4: CI/CD Features (Week 4)\n\n**Goal**: Production-ready with CI integration\n\n**Tasks**:\n1. Implement `--threshold` flag (exit code 3 on violation)\n2. Implement `diff` command (compare two JSON reports)\n3. Add CSV output formatter\n4. Write `.code-viz.toml` config parser\n5. Create GitHub Actions example workflow\n\n**Deliverable**: Shippable MVP with CI/CD examples\n\n## Build and Development Workflow\n\n### Justfile Recipes\n\n```just\n# Development with auto-reload\ndev:\n    cargo watch -x \"run -- analyze .\"\n\n# Run all tests\ntest:\n    cargo nextest run --all-features\n\n# Check code quality\ncheck:\n    cargo fmt --check\n    cargo clippy -- -D warnings\n\n# Build release binary\nrelease:\n    cargo build --release --bin code-viz\n\n# Install locally\ninstall:\n    cargo install --path crates/code-viz-cli\n```\n\n### Cargo Workspace Configuration\n\n```toml\n# Cargo.toml (workspace root)\n[workspace]\nmembers = [\n    \"crates/code-viz-core\",\n    \"crates/code-viz-cli\",\n]\n\n[workspace.dependencies]\nserde = { version = \"1.0\", features = [\"derive\"] }\ntree-sitter = \"0.20\"\n\n[profile.dev]\nopt-level = 1  # Faster incremental builds\n\n[profile.release]\nlto = true         # Link-time optimization\ncodegen-units = 1  # Better runtime performance\n```\n\n### .cargo/config.toml (Linker Optimization)\n\n```toml\n[target.x86_64-unknown-linux-gnu]\nlinker = \"clang\"\nrustflags = [\"-C\", \"link-arg=-fuse-ld=mold\"]\n\n[target.x86_64-apple-darwin]\nrustflags = [\"-C\", \"link-arg=-fuse-ld=ld64\"]\n```\n\n## Security Considerations\n\n- **File System Access**: Read-only (except `.code-viz/cache` writes)\n- **Path Traversal**: Validate paths are within specified root directory\n- **Denial of Service**:\n  - Timeout for Tree-sitter parsing (5 seconds per file)\n  - Max file size limit (skip files >10MB, log warning)\n  - Max directory depth (prevent symlink loops)\n- **No Network**: Completely offline tool\n\n## Future Enhancements (Post-MVP)\n\n- **Language Support**: Add Rust, Python, Go, Java parsers\n- **Cognitive Complexity**: Implement SonarQube's algorithm for nested complexity\n- **Dead Code Detection**: Integrate stack-graphs for reachability analysis\n- **Git Integration**: Correlate metrics with commit history, show churn\n- **GUI Client**: Tauri app that spawns CLI as subprocess, renders treemap from JSON stream\n- **LSP Server**: Embed analysis engine in language server for IDE integration\n",
  "fileStats": {
    "size": 24642,
    "lines": 770,
    "lastModified": "2025-12-15T15:09:11.766Z"
  },
  "comments": []
}